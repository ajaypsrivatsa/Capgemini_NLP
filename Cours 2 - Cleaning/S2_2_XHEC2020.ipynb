{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:env_xhec_nlp]","language":"python","name":"conda-env-env_xhec_nlp-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"S2_2_XHEC2020.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"tVRxDXVer9IL"},"source":["# Imports"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.062633Z","start_time":"2020-01-30T17:25:26.928123Z"},"id":"5ppcz-Exr9IR"},"source":["# Import classiuc and useful libraries\n","import pandas as pd \n","import numpy as np \n","import seaborn \n","import nltk\n","import matplotlib.pyplot as plt\n","from nltk.corpus import stopwords\n","from string import punctuation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehF2U_8Er9IS"},"source":["# Some text"]},{"cell_type":"markdown","metadata":{"id":"evVyAraUr9IS"},"source":["Define a list of words in order to observe the effects of the methods and treatments used."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.075611Z","start_time":"2020-01-30T17:25:30.065754Z"},"id":"W6iXU2O8r9IS"},"source":["my_list = [\"cat\",\"cats\",\"lie\",\"lying\",\"run\",\"running\",\"city\",\"cities\",\"month\",\"monthly\",\"woman\",\"women\", 'better', \"are\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.089252Z","start_time":"2020-01-30T17:25:30.078097Z"},"id":"FpzAJWfHr9IS"},"source":["# Some text\n","sentenceA = 'A stemmer for English operating on the stem cat should identify such strings as cats, catlike, and catty.'\n","sentenceB= 'A stemming algorithm might also reduce the words fishing, fished and fisher to the stem fish.'\n","sentenceC = 'Stemming algorithms are very useful in NLP'\n","sentenceD = \"But it will not help you to catch cats or fishes\"\n","\n","# Regroup sentences into a list \n","sentences = [sentenceA, sentenceB, sentenceC, sentenceD]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cdyVniwr9IT"},"source":["# Introduction to word frequencies"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.104687Z","start_time":"2020-01-30T17:25:30.095205Z"},"code_folding":[1],"id":"Ur1qAAHTr9IT"},"source":["# From 1st part of hands-on. Try to write functions when you write re-usable code.\n","def basic_cleaning(corpus):\n","    \"\"\" Apply basic cleaning to a text corpus\n","    \"\"\"\n","    \n","    corpus = [review.lower() for review in corpus]\n","\n","    token_corpus = [nltk.word_tokenize(review) for review in corpus]\n","\n","    characters_to_remove = [\"@\", \"/\", \"#\", \".\", \",\", \"!\", \"?\", \"(\", \")\", \"-\", \"_\", \"’\", \"'\",\n","                            \"\\\"\", \":\", \"'\", \"$\", \"%\", '&', '£']\n","    stop_words_en = nltk.corpus.stopwords.words(\"english\")\n","    my_stop_words = []\n","#     my_stop_words = ['thought', 'said', 'we', 'food', 'london', 'ever', 'time', 'also', 'one', \n","#                     'restaurant', 'good', 'great', \"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\",\n","#                      '``', 'ca', 'can', 'let', 'must', \"n't\", 'sha', 'wo',\n","#                      'get', 'go', 'like', 'just', 'got']\n","    \n","    all_stop_char = stop_words_en + characters_to_remove + my_stop_words\n","    corpus = [[token for token in review if token not in all_stop_char]\n","              for review in token_corpus]\n","\n","    return corpus, all_stop_char"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.130711Z","start_time":"2020-01-30T17:25:30.109694Z"},"id":"Rk6Cy79Qr9IT"},"source":["sentences_clean, _ = basic_cleaning(sentences)\n","#sentences_clean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twqMjScLr9IU","outputId":"6559cbe5-f91d-43d9-b076-fcc55a899c1d"},"source":["print(sentences[1])\n","print(sentences_clean[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["A stemming algorithm might also reduce the words fishing, fished and fisher to the stem fish.\n","['stemming', 'algorithm', 'might', 'also', 'reduce', 'words', 'fishing', 'fished', 'fisher', 'stem', 'fish']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.138754Z","start_time":"2020-01-30T17:25:30.132234Z"},"id":"qQnjtxvOr9IV","outputId":"2f60b7d6-5a11-4880-db3f-5ce44c609757"},"source":["# Let's see what are all the words used in our sentences\n","vocab = list(set([item for sentence in sentences_clean for item in sentence]))\n","vocab"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['fish',\n"," 'fishes',\n"," 'english',\n"," 'stemmer',\n"," 'cats',\n"," 'catlike',\n"," 'identify',\n"," 'stem',\n"," 'reduce',\n"," 'also',\n"," 'operating',\n"," 'fisher',\n"," 'fished',\n"," 'algorithm',\n"," 'might',\n"," 'cat',\n"," 'catty',\n"," 'strings',\n"," 'help',\n"," 'catch',\n"," 'useful',\n"," 'algorithms',\n"," 'words',\n"," 'fishing',\n"," 'nlp',\n"," 'stemming']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.150102Z","start_time":"2020-01-30T17:25:30.143755Z"},"id":"3mqGCqtQr9IV","outputId":"5c042821-9181-4ca0-adf6-e3c16d9e1bfa"},"source":["# Initialize the vocabulary frequence to zero\n","vocab_freq = {word:0 for word in vocab}\n","vocab_freq"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'fish': 0,\n"," 'fishes': 0,\n"," 'english': 0,\n"," 'stemmer': 0,\n"," 'cats': 0,\n"," 'catlike': 0,\n"," 'identify': 0,\n"," 'stem': 0,\n"," 'reduce': 0,\n"," 'also': 0,\n"," 'operating': 0,\n"," 'fisher': 0,\n"," 'fished': 0,\n"," 'algorithm': 0,\n"," 'might': 0,\n"," 'cat': 0,\n"," 'catty': 0,\n"," 'strings': 0,\n"," 'help': 0,\n"," 'catch': 0,\n"," 'useful': 0,\n"," 'algorithms': 0,\n"," 'words': 0,\n"," 'fishing': 0,\n"," 'nlp': 0,\n"," 'stemming': 0}"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.162262Z","start_time":"2020-01-30T17:25:30.153834Z"},"id":"OIfuVbTXr9IV","outputId":"a2fe4fa8-c5a7-42fb-8a0f-dfe31f9655a1"},"source":["# Now let's calculate our word frequencies. We iterate over words in our sentences, for each word we update the count\n","for sentence in sentences_clean:\n","    for word in sentence:\n","        if word in vocab: \n","            vocab_freq[word] +=1\n","vocab_freq = {k: v for k, v in sorted(vocab_freq.items(), key=lambda item: item[1], reverse=True)}\n","vocab_freq"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'cats': 2,\n"," 'stem': 2,\n"," 'stemming': 2,\n"," 'fish': 1,\n"," 'fishes': 1,\n"," 'english': 1,\n"," 'stemmer': 1,\n"," 'catlike': 1,\n"," 'identify': 1,\n"," 'reduce': 1,\n"," 'also': 1,\n"," 'operating': 1,\n"," 'fisher': 1,\n"," 'fished': 1,\n"," 'algorithm': 1,\n"," 'might': 1,\n"," 'cat': 1,\n"," 'catty': 1,\n"," 'strings': 1,\n"," 'help': 1,\n"," 'catch': 1,\n"," 'useful': 1,\n"," 'algorithms': 1,\n"," 'words': 1,\n"," 'fishing': 1,\n"," 'nlp': 1}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"B92eBH6fr9IW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bJmzGfe4r9IW"},"source":["# Stemming"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.167225Z","start_time":"2020-01-30T17:25:30.164717Z"},"id":"4_zBj9zWr9IW"},"source":["# It exists many different stemmer. Try them ! "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KF5xbP8nr9IW"},"source":["# my_list = [\"cat\",\"cats\",\"lie\",\"lying\",\"run\",\"running\",\"city\",\"cities\",\"month\",\"monthly\",\"woman\",\"women\", 'better', \"are\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.178733Z","start_time":"2020-01-30T17:25:30.169137Z"},"id":"0T6qUuN2r9IW","outputId":"faca7d79-1850-4029-b2fe-b6f306d6148f"},"source":["# Porter Stemmer\n","porter = nltk.PorterStemmer()\n","for word in my_list:\n","    print(porter.stem(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cat\n","cat\n","lie\n","lie\n","run\n","run\n","citi\n","citi\n","month\n","monthli\n","woman\n","women\n","better\n","are\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.191290Z","start_time":"2020-01-30T17:25:30.181388Z"},"id":"0SjEAJwer9IX","outputId":"5c284ecc-0e7a-4511-9860-87cc1b829622"},"source":["# Lancaster Stemmer\n","lancaster = nltk.LancasterStemmer()\n","for word in my_list:\n","    print(lancaster.stem(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cat\n","cat\n","lie\n","lying\n","run\n","run\n","city\n","city\n","mon\n","month\n","wom\n","wom\n","bet\n","ar\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.200753Z","start_time":"2020-01-30T17:25:30.194149Z"},"code_folding":[0],"id":"FAxQ_Zl6r9IX"},"source":["def stemSentence(sentence, stemmer):\n","    \"\"\" Take a string input (sentence preferably), and a specific stemmer.\n","        Outputs the sentence in a string format after having applied the stemmer\n","    \"\"\"\n","    \n","    token_words = nltk.word_tokenize(sentence)\n","    stem_sentence = []\n","    \n","    for word in token_words:\n","        stem_sentence.append(stemmer.stem(word))\n","        stem_sentence.append(\" \")\n","    \n","    return \"\".join(stem_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-31T15:05:21.431447Z","start_time":"2020-01-31T15:05:21.326993Z"},"id":"W67012iAr9IX","outputId":"15b7551b-f4fa-4bde-c7d4-136ad0c6515f"},"source":["# Compare differences\n","sentence=\"I have an important meeting today. The people I'm meeting with always make the right decisions\"\n","\n","print(stemSentence(sentence, lancaster))\n","print(stemSentence(sentence, porter))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["i hav an import meet today . the peopl i 'm meet with alway mak the right decid \n","I have an import meet today . the peopl I 'm meet with alway make the right decis \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.218468Z","start_time":"2020-01-30T17:25:30.210905Z"},"id":"NQ8JrYIlr9IX","outputId":"8604b36d-fd6f-4d3a-ebab-c4ddcbea969e"},"source":["# Look at what is happening on a french sentence\n","sentence=\"Ce matin je suis allé acheter une baguette à la Boulangerie puis je me suis régalé avant de venir en cours.\"\n","\n","print(stemSentence(sentence, lancaster))\n","print(stemSentence(sentence, porter))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ce matin je sui allé achet un baguet à la boulangery pui je me sui régalé av de venir en cour . \n","Ce matin je sui allé achet une baguett à la boulangeri pui je me sui régalé avant de venir en cour . \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2NV92BAKr9IY"},"source":["# Results may be hard to read "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xEQTVOjxr9IY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Xcbs0xMr9IY"},"source":["## Effects on our Sentences "]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.224165Z","start_time":"2020-01-30T17:25:30.221545Z"},"id":"EeRgEGqgr9IY"},"source":["# Let's see the effect of stemming on our vocabulary frequencies"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.231377Z","start_time":"2020-01-30T17:25:30.226077Z"},"id":"-X1uAYtwr9IY"},"source":["stemmed_sentences = []\n","for sentence in sentences_clean:\n","    stem_sentence = []\n","    for word in sentence: \n","        stem_sentence.append(porter.stem(word))\n","#         stem_sentence.append(lancaster.stem(word))\n","        \n","    stemmed_sentences.append(stem_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.241218Z","start_time":"2020-01-30T17:25:30.234124Z"},"id":"cOkwFF23r9IY","outputId":"e6be685b-c22c-4bee-f6bf-334fa8a8ac31"},"source":["stemmed_sentences"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['stemmer',\n","  'english',\n","  'oper',\n","  'stem',\n","  'cat',\n","  'identifi',\n","  'string',\n","  'cat',\n","  'catlik',\n","  'catti'],\n"," ['stem',\n","  'algorithm',\n","  'might',\n","  'also',\n","  'reduc',\n","  'word',\n","  'fish',\n","  'fish',\n","  'fisher',\n","  'stem',\n","  'fish'],\n"," ['stem', 'algorithm', 'use', 'nlp'],\n"," ['help', 'catch', 'cat', 'fish']]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"uujBFO6or9IZ"},"source":["#sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.272285Z","start_time":"2020-01-30T17:25:30.243435Z"},"id":"xPHmbdxOr9IZ","outputId":"2c2a2b0d-2104-44ef-c41b-0ef1edd32c09"},"source":["vocab = list(set([item for sentence in stemmed_sentences for item in sentence]))\n","print(\"Size of vocab:\", len(vocab))\n","vocab_freq = {word:0 for word in vocab}\n","\n","for sentence in stemmed_sentences:\n","    for word in sentence:\n","        if word in vocab: \n","            vocab_freq[word] +=1\n","vocab_freq = {k: v for k, v in sorted(vocab_freq.items(), key=lambda item: item[1], reverse=True)}\n","vocab_freq"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Size of vocab: 20\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'fish': 4,\n"," 'stem': 4,\n"," 'cat': 3,\n"," 'algorithm': 2,\n"," 'english': 1,\n"," 'reduc': 1,\n"," 'stemmer': 1,\n"," 'use': 1,\n"," 'also': 1,\n"," 'fisher': 1,\n"," 'identifi': 1,\n"," 'catlik': 1,\n"," 'might': 1,\n"," 'word': 1,\n"," 'catti': 1,\n"," 'help': 1,\n"," 'catch': 1,\n"," 'oper': 1,\n"," 'string': 1,\n"," 'nlp': 1}"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"EoyTnf4wr9IZ"},"source":["# The stem \"stem\" appears in the first position, this subject is actually the one that is the most mentioned in the sentences. But it keeps stemmer as a different stem \n","# The effect is also visible for the stem 'fish'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h8BylWpLr9IZ"},"source":["# Lemmatizer"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:30.634631Z","start_time":"2020-01-30T17:25:30.274288Z"},"id":"GNnVsPUgr9IZ","outputId":"7a232ed9-9351-43dc-814a-b85e63492207"},"source":["nltk.download('wordnet')\n","wnlem = nltk.WordNetLemmatizer()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to\n","[nltk_data]     /Users/lemeillefrancois/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KPYDvDJGr9Ia"},"source":["# my_list = [\"cat\",\"cats\",\"lie\",\"lying\",\"run\",\"running\",\"city\",\"cities\",\"month\",\"monthly\",\"woman\",\"women\", 'better', \"are\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:32.192538Z","start_time":"2020-01-30T17:25:30.637514Z"},"id":"utK-iujnr9Ia","outputId":"3728f3a3-dc3c-4da7-9fba-d6f920a423dd"},"source":["for word in my_list:\n","    print(wnlem.lemmatize(word))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cat\n","cat\n","lie\n","lying\n","run\n","running\n","city\n","city\n","month\n","monthly\n","woman\n","woman\n","better\n","are\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:32.203103Z","start_time":"2020-01-30T17:25:32.194242Z"},"id":"7r7w_GXvr9Ia","outputId":"69dd360d-e894-475b-d63b-05bb587115d6"},"source":["lemmatizer = nltk.WordNetLemmatizer()\n","\n","# Create lematizing function\n","\n","\n","def lemmatize(sentence):\n","    tokens = nltk.word_tokenize(sentence)\n","    tokens = [lemmatizer.lemmatize(lemmatizer.lemmatize(\n","        lemmatizer.lemmatize(token, pos='a'), pos='v'), pos='n') for token in tokens]\n","    return \" \".join(tokens)\n","\n","\n","# And display results\n","lemmer = lemmatize(\"I have an important meeting today. The people I'm meeting with always make the right decisions\")\n","print(lemmer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["I have an important meet today . The people I 'm meet with always make the right decision\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:32.212439Z","start_time":"2020-01-30T17:25:32.208822Z"},"id":"X7lZoAXir9Ia"},"source":["#  We recommend that you test different lemmatizers, and their parameters to observe their effects ! "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hm1xesI_r9Ia"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4oqZuLrCr9Ib"},"source":["## Effect on our sentences"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:32.227628Z","start_time":"2020-01-30T17:25:32.216489Z"},"id":"8kJiygC4r9Ib"},"source":["# Let's see the effect of lemmatizing on our vocaubulary frequencies"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:32.257472Z","start_time":"2020-01-30T17:25:32.236519Z"},"id":"cN20hNFer9Ib"},"source":["lem_sentences = []\n","lemmatizer = nltk.WordNetLemmatizer()\n","for sentence in sentences_clean:\n","    lem_sentence = []\n","    for word in sentence: \n","        lem_sentence.append(lemmatizer.lemmatize(word))\n","\n","        \n","    lem_sentences.append(lem_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:32.268507Z","start_time":"2020-01-30T17:25:32.259535Z"},"id":"eTR_iMQEr9Ib","outputId":"c6923dbe-c269-4d14-d941-ec172ee48e88"},"source":["lem_sentences"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['stemmer',\n","  'english',\n","  'operating',\n","  'stem',\n","  'cat',\n","  'identify',\n","  'string',\n","  'cat',\n","  'catlike',\n","  'catty'],\n"," ['stemming',\n","  'algorithm',\n","  'might',\n","  'also',\n","  'reduce',\n","  'word',\n","  'fishing',\n","  'fished',\n","  'fisher',\n","  'stem',\n","  'fish'],\n"," ['stemming', 'algorithm', 'useful', 'nlp'],\n"," ['help', 'catch', 'cat', 'fish']]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-01-30T17:25:32.290504Z","start_time":"2020-01-30T17:25:32.276790Z"},"id":"0_s_dU5fr9Ib","outputId":"dd4cb70b-cf34-449f-b633-f6fae37974c0"},"source":["vocab = list(set([item for sentence in lem_sentences for item in sentence]))\n","vocab_freq = {word:0 for word in vocab}\n","print(\"Size of vocab:\", len(vocab))\n","\n","for sentence in lem_sentences:\n","    for word in sentence:\n","        if word in vocab: \n","            vocab_freq[word] +=1\n","vocab_freq = {k: v for k, v in sorted(vocab_freq.items(), key=lambda item: item[1], reverse=True)}\n","vocab_freq"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Size of vocab: 23\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'cat': 3,\n"," 'fish': 2,\n"," 'stem': 2,\n"," 'algorithm': 2,\n"," 'stemming': 2,\n"," 'english': 1,\n"," 'stemmer': 1,\n"," 'catlike': 1,\n"," 'identify': 1,\n"," 'reduce': 1,\n"," 'also': 1,\n"," 'operating': 1,\n"," 'fisher': 1,\n"," 'fished': 1,\n"," 'might': 1,\n"," 'word': 1,\n"," 'catty': 1,\n"," 'help': 1,\n"," 'catch': 1,\n"," 'useful': 1,\n"," 'fishing': 1,\n"," 'string': 1,\n"," 'nlp': 1}"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"50oo69E7r9Ib"},"source":["# The results are differents here. \n","# First the size of vocabulary is slightly larger \n","# We can observe, that as expected, every words in the vocabulary is a proper english word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8d9BK5Jr9Ic"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJ73HY5Fr9Ic"},"source":["### Your turn ! "]},{"cell_type":"code","metadata":{"id":"qYS5y9O8r9Ic"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DpV3Vhw4r9Ic"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2CxP4Wr9r9Ic"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtVihUjOr9Ic"},"source":[""],"execution_count":null,"outputs":[]}]}